{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj3OjoBIh7W-",
        "outputId": "312a7ba1-48b1-4c47-e00a-a2c5b5884fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 32, 32, 64)           1792      ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 32, 32, 64)           256       ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 16, 16, 64)           0         ['batch_normalization_10[0][0]\n",
            " ng2D)                                                              ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 16, 16, 64)           0         ['max_pooling2d_10[0][0]']    \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 16, 16, 64)           4160      ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 16, 16, 128)          73856     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 16, 16, 32)           51232     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 16, 16, 32)           2080      ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 16, 16, 256)          0         ['conv2d_26[0][0]',           \n",
            " )                                                                   'conv2d_27[0][0]',           \n",
            "                                                                     'conv2d_28[0][0]',           \n",
            "                                                                     'conv2d_29[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 65536)                0         ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 512)                  3355494   ['flatten_5[0][0]']           \n",
            "                                                          4                                       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 512)                  2048      ['dense_10[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 512)                  0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 10)                   5130      ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 33695498 (128.54 MB)\n",
            "Trainable params: 33694346 (128.53 MB)\n",
            "Non-trainable params: 1152 (4.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "782/782 [==============================] - 39s 47ms/step - loss: 2.5948 - accuracy: 0.4378 - val_loss: 2.0237 - val_accuracy: 0.5537\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.9507 - accuracy: 0.5510 - val_loss: 1.7463 - val_accuracy: 0.5911\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 1.6141 - accuracy: 0.5986 - val_loss: 1.4593 - val_accuracy: 0.6452\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.4054 - accuracy: 0.6275 - val_loss: 1.3295 - val_accuracy: 0.6468\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 1.2813 - accuracy: 0.6459 - val_loss: 1.2642 - val_accuracy: 0.6426\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.2098 - accuracy: 0.6589 - val_loss: 1.2498 - val_accuracy: 0.6608\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 1.1678 - accuracy: 0.6706 - val_loss: 1.0562 - val_accuracy: 0.7070\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.1546 - accuracy: 0.6771 - val_loss: 1.1835 - val_accuracy: 0.6844\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 36s 47ms/step - loss: 1.1240 - accuracy: 0.6888 - val_loss: 1.2064 - val_accuracy: 0.6884\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.0984 - accuracy: 0.6974 - val_loss: 1.2831 - val_accuracy: 0.6580\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 1.0705 - accuracy: 0.7044 - val_loss: 1.0814 - val_accuracy: 0.7128\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 1.0467 - accuracy: 0.7153 - val_loss: 1.0546 - val_accuracy: 0.7105\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 36s 47ms/step - loss: 1.0288 - accuracy: 0.7185 - val_loss: 0.9887 - val_accuracy: 0.7372\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 1.0047 - accuracy: 0.7260 - val_loss: 1.1267 - val_accuracy: 0.7064\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.0002 - accuracy: 0.7300 - val_loss: 1.0400 - val_accuracy: 0.7296\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.9937 - accuracy: 0.7328 - val_loss: 1.0925 - val_accuracy: 0.7024\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9883 - accuracy: 0.7373 - val_loss: 0.9658 - val_accuracy: 0.7501\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.9838 - accuracy: 0.7381 - val_loss: 0.9640 - val_accuracy: 0.7547\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.9775 - accuracy: 0.7451 - val_loss: 1.0505 - val_accuracy: 0.7321\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.9729 - accuracy: 0.7461 - val_loss: 1.0996 - val_accuracy: 0.7120\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 0.9601 - accuracy: 0.7513 - val_loss: 0.9624 - val_accuracy: 0.7556\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9494 - accuracy: 0.7567 - val_loss: 1.0687 - val_accuracy: 0.7393\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9531 - accuracy: 0.7557 - val_loss: 1.0177 - val_accuracy: 0.7410\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 0.9499 - accuracy: 0.7580 - val_loss: 0.9280 - val_accuracy: 0.7752\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.9418 - accuracy: 0.7638 - val_loss: 0.9985 - val_accuracy: 0.7574\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9353 - accuracy: 0.7684 - val_loss: 1.0431 - val_accuracy: 0.7368\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.9348 - accuracy: 0.7651 - val_loss: 0.9281 - val_accuracy: 0.7735\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9279 - accuracy: 0.7662 - val_loss: 1.0285 - val_accuracy: 0.7448\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.9275 - accuracy: 0.7706 - val_loss: 1.0181 - val_accuracy: 0.7414\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9196 - accuracy: 0.7738 - val_loss: 1.0470 - val_accuracy: 0.7387\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9185 - accuracy: 0.7744 - val_loss: 1.0102 - val_accuracy: 0.7460\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.9239 - accuracy: 0.7754 - val_loss: 0.9371 - val_accuracy: 0.7723\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9134 - accuracy: 0.7767 - val_loss: 0.9621 - val_accuracy: 0.7714\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9051 - accuracy: 0.7800 - val_loss: 0.9776 - val_accuracy: 0.7605\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.9142 - accuracy: 0.7820 - val_loss: 0.9083 - val_accuracy: 0.7868\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.9053 - accuracy: 0.7849 - val_loss: 0.9436 - val_accuracy: 0.7819\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.9022 - accuracy: 0.7857 - val_loss: 0.9508 - val_accuracy: 0.7799\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.9011 - accuracy: 0.7893 - val_loss: 1.0453 - val_accuracy: 0.7615\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.9002 - accuracy: 0.7881 - val_loss: 1.0031 - val_accuracy: 0.7652\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.9007 - accuracy: 0.7906 - val_loss: 1.0053 - val_accuracy: 0.7592\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.8973 - accuracy: 0.7900 - val_loss: 0.9350 - val_accuracy: 0.7921\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.8950 - accuracy: 0.7909 - val_loss: 0.8952 - val_accuracy: 0.7984\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.8928 - accuracy: 0.7928 - val_loss: 0.9369 - val_accuracy: 0.7794\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8913 - accuracy: 0.7956 - val_loss: 0.9688 - val_accuracy: 0.7810\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 0.8848 - accuracy: 0.7970 - val_loss: 0.9201 - val_accuracy: 0.7954\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.8874 - accuracy: 0.7970 - val_loss: 1.0627 - val_accuracy: 0.7503\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.8858 - accuracy: 0.7987 - val_loss: 0.9354 - val_accuracy: 0.7897\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.8832 - accuracy: 0.7998 - val_loss: 0.9725 - val_accuracy: 0.7875\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 0.8832 - accuracy: 0.8002 - val_loss: 0.9179 - val_accuracy: 0.7941\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 0.8790 - accuracy: 0.8029 - val_loss: 0.8831 - val_accuracy: 0.8067\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to between 0 and 1\n",
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
        "\n",
        "# Apply data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Define Inception module\n",
        "def inception_module(x, filters):\n",
        "    conv1x1_1 = layers.Conv2D(filters[0], (1, 1), padding='same', activation='relu')(x)\n",
        "    conv3x3 = layers.Conv2D(filters[1], (3, 3), padding='same', activation='relu')(x)\n",
        "    conv5x5 = layers.Conv2D(filters[2], (5, 5), padding='same', activation='relu')(x)\n",
        "    maxpool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    maxpool_conv1x1 = layers.Conv2D(filters[3], (1, 1), padding='same', activation='relu')(maxpool)\n",
        "    inception = layers.concatenate([conv1x1_1, conv3x3, conv5x5, maxpool_conv1x1], axis=-1)\n",
        "    return inception\n",
        "\n",
        "# Build the CNN model with Inception module using Model API\n",
        "input_layer = layers.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = inception_module(x, [64, 128, 32, 32])\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output_layer = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model with data augmentation\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                    epochs=50,\n",
        "                    validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFCR0IDVh8z3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}